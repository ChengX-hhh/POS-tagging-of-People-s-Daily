{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f45905f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-12T01:05:37.912578Z",
     "start_time": "2023-04-12T01:05:37.891577Z"
    }
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6615bff",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1977edae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-12T01:05:39.789593Z",
     "start_time": "2023-04-12T01:05:38.661577Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('train.txt', 'r', encoding='UTF-8') as f:\n",
    "    train_sents = []\n",
    "    for sent in f:\n",
    "        # Split each sentence and extract each word and its corresponding tagging\n",
    "        token_tag_list = [i.strip('[]').split('/') for i in sent.strip().split() if i]\n",
    "        train_sents.append(token_tag_list)\n",
    "        \n",
    "        \n",
    "with open('test.txt', 'r', encoding='UTF-8') as f:\n",
    "    test_sents = []\n",
    "    for sent in f:\n",
    "        # Split each sentence and extract each word and its corresponding tagging\n",
    "        token_tag_list = [i.strip('[]').split('/') for i in sent.strip().split() if i]\n",
    "        test_sents.append(token_tag_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51698d2a",
   "metadata": {},
   "source": [
    "# Feature function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae7d4dd",
   "metadata": {},
   "source": [
    "T(·) is a multi-valued function, it classifies a character into four classifications: number, date, English letter and others (returns 1, 2, 3 and 4, respectively) (Jiang, et al., 2009)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "937f6ba5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-12T01:05:40.292149Z",
     "start_time": "2023-04-12T01:05:40.274118Z"
    }
   },
   "outputs": [],
   "source": [
    "from zhon.hanzi import punctuation\n",
    "\n",
    "def T(word):\n",
    "    if word.isdigit() or word in ['零','一','二','三','四','五','六','七','八','九','〇']:\n",
    "        return '1'\n",
    "    elif word in ['-', '/', ':','年','月','日','时','分','秒']:\n",
    "        return '2'\n",
    "    elif bool(re.match(\"^[A-Za-z]+$\", word)):\n",
    "        return '3'\n",
    "    else:\n",
    "        return '4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06a41e49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-12T01:05:41.476143Z",
     "start_time": "2023-04-12T01:05:41.463116Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'11243'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example\n",
    "word = '九〇年代R'\n",
    "result = []\n",
    "for w in word:\n",
    "    result.append(T(w))\n",
    "result_str = \"\".join(result)\n",
    "result_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8c83f3d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T08:50:49.592415Z",
     "start_time": "2023-04-11T08:50:49.575448Z"
    }
   },
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    word_T = []\n",
    "    word_T.append(T(word))\n",
    "    \n",
    "    features = {\n",
    "        'word': word,\n",
    "        'len(word)': len(word),\n",
    "        'word.ispunctuation': (word in punctuation)\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        word_T.append(T(word1))\n",
    "        features.update({\n",
    "            '-1:word': word1,\n",
    "            '-1:len(word)': len(word1),\n",
    "            '-1:word.ispunctuation': (word1 in punctuation)\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i > 1:\n",
    "        word2 = sent[i-2][0]\n",
    "        word_T.append(T(word2))\n",
    "        features.update({\n",
    "            '-2:word': word2,\n",
    "            '-2:len(word)': len(word2),\n",
    "            '-2:word.ispunctuation': (word2 in punctuation)\n",
    "        })\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        word_T.append(T(word1))\n",
    "        features.update({\n",
    "            '+1:word': word1,\n",
    "            '+1:len(word)': len(word1),\n",
    "            '+1:word.ispunctuation': (word1 in punctuation),\n",
    "        })\n",
    "\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "    if i < len(sent) - 2:\n",
    "        word2 = sent[i+2][0]\n",
    "        word_T.append(T(word2))\n",
    "        features.update({\n",
    "            '+2:word': word2,\n",
    "            '+2:len(word)': len(word2),\n",
    "            '+2:word.ispunctuation': (word2 in punctuation)\n",
    "        })\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [word[1] for word in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [word[0] for word in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f81effa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text_analysis",
   "language": "python",
   "name": "text_analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
